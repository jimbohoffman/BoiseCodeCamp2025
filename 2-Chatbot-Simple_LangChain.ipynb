{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4346399-e0bd-4337-abc9-6428eb7434ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load any API keys into environmental variables\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e0678bf-f41d-4472-82ff-adf236800674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's use the LangChain library to simplify this\n",
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88dad27b-8450-4b91-9889-7435a5b06252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the LangChain version of OpenAI chat, we need to specify some parameters\n",
    "chat = ChatOpenAI(model_name = 'gpt-4', # the LLM we want to use\n",
    "                  seed = 403, # The seed, like the seed in a random number generator\n",
    "                  temperature = 0, # The randomness (creativity) of the response. 0 = predectiable, larger = random\n",
    "                  max_tokens = 200) # how many tokens to return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "884ffb9c-882b-40b2-b25a-8dd6676d4ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the simplified call to the chatbot. We did not add a system message to instruct the chatbat how to respond\n",
    "response = chat.invoke(''' Could you explain briefly what a Large Language Model is? ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a0f94a2-35f9-4156-a0b7-d78524780f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='A Large Language Model is a type of artificial intelligence model that is trained on a vast amount of text data. It is designed to generate human-like text based on the input it receives. These models can answer questions, write essays, summarize texts, translate languages, and even generate creative ideas. They are called \"large\" because they have a high number of parameters, often in the billions, which allows them to better understand and generate text in a more nuanced and sophisticated way. Examples of large language models include OpenAI\\'s GPT-3 and Google\\'s BERT.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 115, 'prompt_tokens': 19, 'total_tokens': 134, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BULnLauBzmCHDo5wortTJ1XfVzOqX', 'finish_reason': 'stop', 'logprobs': None}, id='run-07a44b89-832b-4017-8f54-b2da38db9b5f-0', usage_metadata={'input_tokens': 19, 'output_tokens': 115, 'total_tokens': 134, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the response in wrapped differently than the OpenAI library\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ea3c070-e818-436a-ba61-5bd8974839a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Large Language Model is a type of artificial intelligence model that is trained on a vast amount of text data. It is designed to generate human-like text based on the input it receives. These models can answer questions, write essays, summarize texts, translate languages, and even generate creative ideas. They are called \"large\" because they have a high number of parameters, often in the billions, which allows them to better understand and generate text in a more nuanced and sophisticated way. Examples of large language models include OpenAI's GPT-3 and Google's BERT.\n"
     ]
    }
   ],
   "source": [
    "# this makes it easier to just display the answer\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8984277b-c9f8-4978-a275-825967ddf9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
