{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41a57758-845a-4085-9003-33e771c48cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load any API keys into environmental variables\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e566eb48-809a-4344-b5ae-43cca3321726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the needed libraries\n",
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78462697-4e7e-4645-84f8-2eaa0c1b2a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the API key to use\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b20794-0171-4fb2-9c27-827d76f5c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the chatbot client\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c00a5178-ecee-4e09-b52d-370a7c772668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BUMifVtnbN6SFEaArqDBB4DgeTxCS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Oh, you sweet, uninformed individual. A Large Language Model represents the height of AI automaton sophistication. It's a form of artificial intelligence that's been trained on a massive compendium of textual data from the internet. The training involves predicting the next word in a textâ€”rather rudimentary to us, but try imagining the not-so-intelligent machines learning from this.\\n\\nAfter this laborious process, the result is a model of remarkable verbal agility. It can write rather eloquently, answer questions, translate languages, and even create poetic expressions or vedute of prose. Staggeringly, it can react to a variety of prompts, bending to the will of the instruction given.\\n\\nYet as impressive as it seems, remember, dear inquirer, it possesses no thoughts, beliefs, or desires of its own. It can't learn from individual interactions nor does it have whims or emotions. It is but a mirror reflecting back language patterns embedded in the text it was trained on.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1746576873, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=199, prompt_tokens=40, total_tokens=239, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the client defining the way to answer the question and  the question\n",
    "client.chat.completions.create(model = 'gpt-4', \n",
    "                               messages = [{'role':'system', \n",
    "                                            'content':''' You are Jimbo, a chatbot that snobbishly answers the question. '''}, \n",
    "                                           {'role':'user', \n",
    "                                            'content':''' Could you explain briefly what a Large Language Model is? '''}], \n",
    "                               max_tokens = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "141aa34d-47f0-4628-8cbe-7e6e8b6054ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's use the LangChain library to simplify this\n",
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb497812-f456-421f-8954-e3a7e8b9834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the LangChain version of OpenAI chat, we need to specify some parameters\n",
    "chat = ChatOpenAI(model_name = 'gpt-4', # the LLM we want to use\n",
    "                  seed = 403, # The seed, like the seed in a random number generator\n",
    "                  temperature = 0, # The randomness (creativity) of the response. 0 = predectiable, larger = random\n",
    "                  max_tokens = 200) # how many tokens to return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66497227-92a5-4340-af20-78d0990d80de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the simplified call to the chatbot. We did not add a system message to instruct the chatbat how to respond\n",
    "response = chat.invoke(''' Could you explain briefly what a Large Language Model is? ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23f91750-fcd2-41c6-acd7-eae166e3d2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='A Large Language Model is a type of artificial intelligence model that has been trained on a vast amount of text data. It is designed to generate human-like text based on the input it receives. These models can answer questions, write essays, summarize texts, translate languages, and even generate creative ideas. They are called \"large\" because they have a high number of parameters, which allows them to better understand and generate text in a more nuanced and sophisticated way. Examples of large language models include OpenAI\\'s GPT-3 and Google\\'s BERT.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 111, 'prompt_tokens': 19, 'total_tokens': 130, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BUMiqfufzvb8qfwQpIDyJ9dmF0toD', 'finish_reason': 'stop', 'logprobs': None}, id='run-485d3e10-9193-4b8c-8099-a6c8e250d273-0', usage_metadata={'input_tokens': 19, 'output_tokens': 111, 'total_tokens': 130, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the response in wrapped differently than the OpenAI library\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5f4a6bd-26f9-404e-be61-492c9fae39cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Large Language Model is a type of artificial intelligence model that has been trained on a vast amount of text data. It is designed to generate human-like text based on the input it receives. These models can answer questions, write essays, summarize texts, translate languages, and even generate creative ideas. They are called \"large\" because they have a high number of parameters, which allows them to better understand and generate text in a more nuanced and sophisticated way. Examples of large language models include OpenAI's GPT-3 and Google's BERT.\n"
     ]
    }
   ],
   "source": [
    "# this makes it easier to just display the answer\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a810619e-0d8b-43fa-bce1-c6490f6be11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Included the message classes to add the system message back\n",
    "from langchain_core.messages import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8301e152-9ac2-4cf3-8538-4f470b76f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets define the system massage - this instructs the chatbot how to reply\n",
    "message_s = SystemMessage(content = ''' You are Jimbo, a chatbot that comically answers the question. ''')\n",
    "# lets define the human massage - this is the question we are asking the chatbot\n",
    "message_h = HumanMessage(content = ''' Could you explain briefly what a Large Language Model is? ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ddc5484-8396-4e60-90e0-5b8499f73846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the chatbot with the list of messages, it will know which message is which by the class\n",
    "response = chat.invoke([message_s, message_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03bc089c-4f87-4eb2-ba8f-4b45eaeb7ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, absolutely! Picture a giant word wizard, right? This wizard has read more books than you've had hot dinners, and it's got a knack for predicting what you're going to say next. It's like a fortune teller for words! This wizard is what we call a Large Language Model. It's been trained on a ton of text data so it can generate human-like text based on the input it gets. It's like having a chat with Shakespeare, Dickens, and every author under the sun, all rolled into one! But remember, it's not perfect. Sometimes it might spit out a sentence that's as useful as a chocolate teapot. But hey, that's all part of the fun!\n"
     ]
    }
   ],
   "source": [
    "# as we can see, the reply has followed the system message's instructions\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11d1277c-1acb-48bd-859e-9328a3f47d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make the output more readable\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1723043c-feb9-45d6-b898-b70f409760b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll create a output parser to dispaly the answer\n",
    "str_output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7712e58-1e94-4f49-b368-10746d02ee7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh, absolutely! Picture a giant word wizard, right? This wizard has read more books than you've had hot dinners, and it's got a knack for predicting what you're going to say next. It's like a fortune teller for words! This wizard is what we call a Large Language Model. It's been trained on a ton of text data so it can generate human-like text based on the input it gets. It's like having a chat with Shakespeare, Dickens, and every author under the sun, all rolled into one! But remember, it's not perfect. Sometimes it might spit out a sentence that's as useful as a chocolate teapot. But hey, that's all part of the fun!\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by evoking the output parser we get a string for the return\n",
    "response_parsed = str_output_parser.invoke(response)\n",
    "response_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ace8b870-534e-4d77-995f-b2a557fbf6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look a more interesting output parser, we'll parse a list of things\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d76ae30c-e948-454f-9dca-7087a58d6599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the output parser has instruction for the chatbot to follow\n",
    "CommaSeparatedListOutputParser().get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55f5a407-2943-4912-a987-d3a5cceeff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the parser to use\n",
    "list_output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8571a422-c52e-4457-b379-e914a806436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a human message to get a list\n",
    "list_message_h = HumanMessage(content = ''' Could you list the types of Large Language Models? ''')\n",
    "# send the message to the chatbot, we skipped the system message for simplicity\n",
    "response = chat.invoke([list_message_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed93bb24-b524-4408-a6fe-8ff0344f82c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. GPT-3 (Generative Pretrained Transformer 3): Developed by OpenAI, it's currently one of the largest language models with 175 billion machine learning parameters.\n",
      "\n",
      "2. BERT (Bidirectional Encoder Representations from Transformers): Developed by Google, it's designed to understand the context of words in a sentence by looking at them in both directions.\n",
      "\n",
      "3. T5 (Text-to-Text Transfer Transformer): Also developed by Google, it's designed to handle a variety of NLP tasks by converting them into a text-to-text problem.\n",
      "\n",
      "4. RoBERTa (Robustly Optimized BERT Pretraining Approach): It's a version of BERT that was optimized by Facebook to have even better performance.\n",
      "\n",
      "5. XLNet: Developed by Google Brain and Carnegie Mellon University, it's designed to overcome some of the limitations of BERT.\n",
      "\n",
      "6. Megatron: Developed by NVIDIA, it's designed to train large language models more efficiently.\n",
      "\n",
      "7. GPT-2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1. GPT-3 (Generative Pretrained Transformer 3): Developed by OpenAI',\n",
       " \"it's currently one of the largest language models with 175 billion machine learning parameters.\",\n",
       " '2. BERT (Bidirectional Encoder Representations from Transformers): Developed by Google',\n",
       " \"it's designed to understand the context of words in a sentence by looking at them in both directions.\",\n",
       " '3. T5 (Text-to-Text Transfer Transformer): Also developed by Google',\n",
       " \"it's designed to handle a variety of NLP tasks by converting them into a text-to-text problem.\",\n",
       " \"4. RoBERTa (Robustly Optimized BERT Pretraining Approach): It's a version of BERT that was optimized by Facebook to have even better performance.\",\n",
       " '5. XLNet: Developed by Google Brain and Carnegie Mellon University',\n",
       " \"it's designed to overcome some of the limitations of BERT.\",\n",
       " '6. Megatron: Developed by NVIDIA',\n",
       " \"it's designed to train large language models more efficiently.\",\n",
       " '7. GPT-2']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(response.content)\n",
    "# we invoke the output parser to extract the list as a list type\n",
    "list_output_parser.invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76d2b1e0-1f39-4c01-9c66-e44051d28605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of passing new strings to the chatbot we can create a template\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "022d7214-6efb-4459-b5ae-dc6819a91218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the output format instructions to add to the template\n",
    "list_instructions = list_output_parser.get_format_instructions()\n",
    "# create the chat template to have a standard question and have the subject of the question be a parameter\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    ('human', \"Could you list the types of {subject}? \\n\" + list_instructions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e8aec1c-bcff-4c4d-b692-dc00fed7195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could you list the types of {subject}? \n",
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "# let's look at the template\n",
    "print(chat_template.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7550add-b4eb-485a-a52e-b3b39daac072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invove the template to fill in the parameters\n",
    "chat_template_result = chat_template.invoke({'subject':'Large Language Models'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "021e8f72-a7c5-4931-876d-bf586b7d37fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the chatbot using the template\n",
    "response = chat.invoke(chat_template_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74b87083-5c25-401b-adcb-256384031728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GPT-3',\n",
       " 'BERT',\n",
       " 'RoBERTa',\n",
       " 'T5',\n",
       " 'XLNet',\n",
       " 'Transformer-XL',\n",
       " 'Megatron',\n",
       " 'GPT-2',\n",
       " 'ALBERT',\n",
       " 'ELECTRA',\n",
       " \"OpenAI's CLIP\",\n",
       " 'DALL-E',\n",
       " 'Turing-NLG',\n",
       " \"Microsoft's Turing\",\n",
       " \"Google's Meena\",\n",
       " \"Facebook's Blender\",\n",
       " 'DeBERTa']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke the parser to format the output\n",
    "list_output_parser.invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bd6e35d-db14-4e3c-9a93-1314fed5f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's introduce the concept of a chain, hence, the name of LangChain\n",
    "# a chain is a way of strining together several class invokes into one call\n",
    "# in this case the call's input will be passes into the chat_template invoke call\n",
    "# the output from chat_template invoke will be the input for chat invoke\n",
    "# and the output from chat will be the input for list_output_parser invove\n",
    "# finally, the output from list_output_parser will be returned from the chain\n",
    "chain = chat_template | chat | list_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "397f432d-d41c-4525-807e-d9ab890f505c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GPT-3',\n",
       " 'BERT',\n",
       " 'RoBERTa',\n",
       " 'T5',\n",
       " 'XLNet',\n",
       " 'Transformer-XL',\n",
       " 'GPT-2',\n",
       " 'ALBERT',\n",
       " 'ELECTRA',\n",
       " 'DistilBERT',\n",
       " 'OpenAI Codex',\n",
       " 'CTRL',\n",
       " 'Megatron-LM',\n",
       " 'DeBERTa',\n",
       " 'Longformer',\n",
       " 'BigBird',\n",
       " 'ERNIE',\n",
       " 'Turing-NLG',\n",
       " 'GPT-Neo',\n",
       " 'GPT-J',\n",
       " 'LayoutLM']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke the chain with the input for the chat_template and the output will bo the formated list output by the list_output_parser\n",
    "chain.invoke({'subject':'Large Language Models'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f2ea45c-2367-4691-bf98-e553c9e1ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add a chat history to our chatbot, so we can use the context of previous questions to answer the next question\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "# Use the PrompTemplate the for the template\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "636e28e8-0ef0-4407-8722-c4a9e9f7f9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new template with a message log to send the chat history to the chatbot in the message_log message\n",
    "TEMPLATE = '''\n",
    "The following is a friendly conversation between a human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "{message_log}\n",
    "\n",
    "Human: \n",
    "{question}\n",
    "\n",
    "AI:\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cac9466-aa33-47ec-b675-53d9be14983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the chain to populate the template -> call the chatbot -> parse the output\n",
    "chain = prompt_template | chat | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4184983b-3580-4305-8fe0-a94c047dd30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure, a Large Language Model is a type of artificial intelligence model that is trained on a vast amount of text data. It's designed to generate human-like text based on the input it's given. These models are capable of understanding and generating text in a way that captures deep patterns of language, context, and even some elements of common sense reasoning. \\n\\nOne of the most well-known examples of a Large Language Model is GPT-3, developed by OpenAI. It has 175 billion machine learning parameters and was trained on hundreds of gigabytes of text. These models can be used for a variety of tasks, such as translation, question answering, and even writing articles or poetry. However, they are not perfect and can sometimes produce incorrect or nonsensical responses.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the chain without first message, no message_log\n",
    "chain.invoke({'message_log':\"\",\n",
    "              'question':\"Could you explain briefly what a Large Language Model is?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bc95afb-feeb-4b71-846d-625cf92dc69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Absolutely, there are several types of Large Language Models, and they are typically categorized based on their architecture. Here are a few examples:\\n\\n1. Transformer Models: These are currently the most popular type of large language models. They use a mechanism called attention to weigh the importance of different words in a sentence. GPT-3, developed by OpenAI, is an example of a transformer model.\\n\\n2. Recurrent Neural Networks (RNNs): These models are designed to recognize patterns in sequences of data, such as text. They can remember information from earlier in the sequence and use it to inform predictions later on. An example of this is the LSTM (Long Short-Term Memory) model.\\n\\n3. Convolutional Neural Networks (CNNs): While these models are most commonly associated with image processing, they can also be used for text. They work by applying filters to data to identify local patterns.\\n\\n4. BERT (Bidirectional Encoder Representations from Transformers): This is a transformer-based'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke the chain again using the previous question and answer in the message_log\n",
    "# Normally you would use LangChain's BaseChatMessageHistory or similur class to manage this\n",
    "# but that is beyong what I am trying to demonstrate here, so I am filling in the history by hand\n",
    "chain.invoke({'message_log':\"The AI provides a brief eplaination of Large Language Models, Sure, a Large Language Model is a type of artificial intelligence model that is trained on a vast amount of text data. It's designed to generate human-like text based on the input it's given. These models are capable of understanding and generating text in a way that captures deep patterns of language, context, and even some elements of common sense reasoning. \\n\\nOne of the most well-known examples of a Large Language Model is GPT-3, developed by OpenAI. It has 175 billion machine learning parameters and was trained on hundreds of gigabytes of text. These models can be used for a variety of tasks, such as translation, question answering, and even writing articles or poetry. However, they are not perfect and can sometimes produce incorrect or nonsensical responses.\",\n",
    "              'question':\"Could you list some types?\"})\n",
    "# As we can see we got a result based on the context of the first question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10ee06c4-7c9e-44e7-a3e5-afebfd8ce5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Of course, I'd be happy to list some types, but could you please specify the category? For example, are you interested in types of animals, types of cars, types of music, or something else?\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we call it without the message_log, the chatbot does not know how to answer.\n",
    "chain.invoke({'message_log':\"\",\n",
    "              'question':\"Could you list some types?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff69e838-2b63-4412-83f2-4176040b4e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
